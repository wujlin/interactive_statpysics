{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# P05: Congestion Phase Transition & Universality (PhD Level)\n",
                "\n",
                "## 1. Introduction: Traffic as a Many-Body System\n",
                "\n",
                "Traffic flow exhibits a non-equilibrium phase transition from **Free Flow** (gas-like) to **Congested Flow** (liquid/solid-like). \n",
                "The **Nagel-Schreckenberg (NaSch)** model is the Ising model of traffic: simple, yet capturing the essential physics of spontaneous symmetry breaking (jam formation).\n",
                "\n",
                "In this PhD-level notebook, we will not just \"see\" the jam. We will prove the nature of this phase transition using **Finite Size Scaling (FSS)**, a rigorous technique to extract universal critical exponents from finite simulations.\n",
                "\n",
                "### Core Mappings\n",
                "| Traffic Physics | Statistical Physics |\n",
                "| :--- | :--- |\n",
                "| Car Density $\\rho$ | Temperature $T$ (Control Parameter) |\n",
                "| Average Flow $J$ | Order Parameter $M$ (Magnetization) |\n",
                "| Variance of Flow $\\chi$ | Susceptibility $\\chi$ (Response) |\n",
                "| Critical Density $\\rho_c$ | Critical Temperature $T_c$ |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The Model: Nagel-Schreckenberg (NaSch)\n",
                "\n",
                "Rules for update (parallel):\n",
                "1. **Accelerate**: $v_i \\to \\min(v_i + 1, v_{\\max})$\n",
                "2. **Decelerate**: $v_i \\to \\min(v_i, d_i - 1)$ (avoid collision, $d_i$ is gap)\n",
                "3. **Randomization**: With prob $p$, $v_i \\to \\max(v_i - 1, 0)$ (human error/delay)\n",
                "4. **Move**: $x_i \\to x_i + v_i$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def simulate_nasch(L, rho, v_max=5, p=0.3, steps=1000, trans=200):\n",
                "    N = int(L * rho)\n",
                "    # Initialize uniformly\n",
                "    pos = np.sort(np.random.choice(L, N, replace=False))\n",
                "    vel = np.random.randint(0, v_max + 1, N)\n",
                "    \n",
                "    params = {'L': L, 'N': N, 'v_max': v_max, 'p': p}\n",
                "    \n",
                "    mean_vels = []\n",
                "    flows = []\n",
                "    \n",
                "    for t in range(steps):\n",
                "        # Calculate gaps (periodic boundary)\n",
                "        gaps = (np.roll(pos, -1) - pos) % L\n",
                "        # The last car's gap needs correction for PBC\n",
                "        gaps[-1] = (pos[0] + L) - pos[-1]\n",
                "        # Distance is gap - 1 (empty cells)\n",
                "        dist = gaps - 1\n",
                "        \n",
                "        # 1. Accelerate\n",
                "        vel = np.minimum(vel + 1, v_max)\n",
                "        # 2. Decelerate\n",
                "        vel = np.minimum(vel, dist)\n",
                "        # 3. Randomize\n",
                "        mask = np.random.rand(N) < p\n",
                "        vel = np.maximum(vel - mask, 0)\n",
                "        # 4. Move\n",
                "        pos = (pos + vel) % L\n",
                "        \n",
                "        if t > trans:\n",
                "            # Record observables\n",
                "            # Flow J = density * mean_velocity = (N/L) * avg(v)\n",
                "            # Or simply: sum(v) / L (flux through a point)\n",
                "            J = np.sum(vel) / L\n",
                "            flows.append(J)\n",
                "            \n",
                "    return np.array(flows)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Finite Size Scaling (FSS)\n",
                "\n",
                "Near a critical point, the correlation length diverges: $\\xi \\sim |\\rho - \\rho_c|^{-\\nu}$.\n",
                "In a finite system of size $L$, scaling cuts off when $\\xi \\sim L$.\n",
                "\n",
                "We define the \"susceptibility\" $\\chi$ as the fluctuation of the order parameter (Flow $J$):\n",
                "$$ \\chi = L \\cdot \\text{Var}(J) $$\n",
                "\n",
                "According to FSS hypothesis, near $\\rho_c$:\n",
                "$$ \\chi(L, \\rho) \\sim L^{\\gamma/\\nu} \\tilde{\\chi}\\left((\\rho - \\rho_c)L^{1/\\nu}\\right) $$\n",
                "\n",
                "If we find the correct exponents $\\gamma, \\nu$ and critical point $\\rho_c$, plotting $\\chi L^{-\\gamma/\\nu}$ vs $(\\rho - \\rho_c)L^{1/\\nu}$ should make curves for different $L$ **collapse onto a single master curve**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulation Parameters\n",
                "Ls = [100, 200, 400] # Different system sizes\n",
                "rhos = np.linspace(0.05, 0.5, 30)\n",
                "v_max = 5\n",
                "p = 0.3 # Moderate noise\n",
                "\n",
                "results = {}\n",
                "\n",
                "print(\"Running simulations...\")\n",
                "for L in Ls:\n",
                "    chis = []\n",
                "    Js = []\n",
                "    for rho in tqdm(rhos, desc=f\"L={L}\"):\n",
                "        flows = simulate_nasch(L, rho, v_max, p, steps=2000, trans=500)\n",
                "        # Susceptibility = L * Var(J)\n",
                "        chi = L * np.var(flows)\n",
                "        chis.append(chi)\n",
                "        Js.append(np.mean(flows))\n",
                "    results[L] = {'rho': rhos, 'J': Js, 'chi': chis}\n",
                "\n",
                "# First plot: Raw data\n",
                "plt.figure(figsize=(10, 5))\n",
                "for L in Ls:\n",
                "    plt.plot(results[L]['rho'], results[L]['chi'], 'o-', label=f'L={L}')\n",
                "plt.xlabel(r'Density $\\rho$')\n",
                "plt.ylabel(r'Susceptibility $\\chi$')\n",
                "plt.title('Fluctuations peak near Critical Point')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Collapse (The \"Gold Standard\" of Proof)\n",
                "\n",
                "Now we try to collapse these curves. This requires tuning $\\rho_c, \\nu, \\gamma$ manually or via optimization.\n",
                "For 1D traffic models like NaSch, values are often non-trivial (unlike 2D Ising).\n",
                "Empirically, for $v_{max}=5, p=0.3$, the transition is smoothened, but we can look for the best overlap."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_fss(results, Ls, rho_c, nu, gamma):\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    for L in Ls:\n",
                "        rho = results[L]['rho']\n",
                "        chi = np.array(results[L]['chi'])\n",
                "        \n",
                "        # X axis: (rho - rho_c) * L^(1/nu)\n",
                "        x_scaled = (rho - rho_c) * (L**(1/nu))\n",
                "        # Y axis: chi * L^(-gamma/nu)\n",
                "        y_scaled = chi * (L**(-gamma/nu))\n",
                "        \n",
                "        plt.plot(x_scaled, y_scaled, 'o-', label=f'L={L}', alpha=0.7)\n",
                "        \n",
                "    plt.xlabel(r'$(\\rho - \\rho_c) L^{1/\\nu}$')\n",
                "    plt.ylabel(r'$\\chi L^{-\\gamma/\\nu}$')\n",
                "    plt.title(f'Data Collapse Check\\n$\\rho_c={rho_c}, \\nu={nu}, \\gamma={gamma}$')\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.show()\n",
                "\n",
                "# Try some guess values (you can interactively tune these)\n",
                "# Critical density is usually around 1/(v_max + 1) to 1/v_max depending on noise\n",
                "# For v_max=5, maybe around 0.1-0.2\n",
                "plot_fss(results, Ls, rho_c=0.15, nu=1.5, gamma=1.0)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}