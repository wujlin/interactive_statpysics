{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# P02: From Boltzmann to Choice (PhD Level)\n",
                "\n",
                "## 1. Introduction: The Statistical Mechanics of Decision Making\n",
                "\n",
                "In undergraduate courses, the **Multinomial Logit (MNL)** model is often presented simply as a formula:\n",
                "$$ P_n(i) = \\frac{e^{\\beta V_{ni}}}{\\sum_j e^{\\beta V_{nj}}} $$\n",
                "\n",
                "In this PhD-level notebook, we will derive this from first principles (**Random Utility Maximization**), expose its fundamental limitation (**IIA property**), and resolve it using a hierarchical structure (**Nested Logit**). Finally, we will prove that the denominator of the Logit model is exactly the **Partition Function ($Z$)** and relates directly to **Consumer Surplus (Free Energy)**.\n",
                "\n",
                "### Core Mappings\n",
                "| Urban Economics (RUM) | Statistical Physics (Canonical Ensemble) |\n",
                "| :--- | :--- |\n",
                "| Utility $U_j = V_j + \\varepsilon_j$ | Energy $E_j$ (with thermal noise) |\n",
                "| Deterministic Utility $V_j$ | Ground State Energy $-E_j$ |\n",
                "| Sensitivity $\\beta$ | Inverse Temperature $\\beta = 1/k_B T$ |\n",
                "| Gumbel Noise $\\varepsilon$ | Heat Bath Fluctuations |\n",
                "| Choice Probability $P(j)$ | Boltzmann Factor $\\frac{1}{Z}e^{-\\beta E_j}$ |\n",
                "| **Logsum** $\\ln \\sum e^{\\beta V_j}$ | **Free Energy** $F = -k_B T \\ln Z$ |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Derivation: Why Gumbel?\n",
                "\n",
                "Why does the error term $\\varepsilon$ have to be Gumbel distributed for the choice probability to be Logit (Boltzmann)?\n",
                "\n",
                "If $U_j = V_j + \\varepsilon_j$, and we choose $j$ if $U_j > U_k \\forall k \\neq j$. \n",
                "If $\\varepsilon$ follows a **Gumbel(0, $\\mu$)** distribution:\n",
                "$$ f(\\varepsilon) = \\mu e^{-\\mu(\\varepsilon + e^{-\\mu \\varepsilon})} $$\n",
                "Then the max of i.i.d Gumbel variables is also Gumbel (stability), and the difference of two Gumbel variables is Logistic distributed.\n",
                "\n",
                "This stability property is analogous to how **Gaussian** is stable under addition (Central Limit Theorem). **Gumbel** is stable under maximization (Extreme Value Theory)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import scipy.optimize as opt\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. The Red Bus / Blue Bus Paradox (IIA Failure)\n",
                "\n",
                "The standard MNL assumes **Independence of Irrelevant Alternatives (IIA)**: $\\frac{P(A)}{P(B)}$ should not depend on whether option C exists.\n",
                "\n",
                "**Scenario**:\n",
                "- Originally: Car vs Red Bus. Utilities equal ($V_{car} = V_{red}$). $P(Car)=0.5, P(Red)=0.5$.\n",
                "- Disruption: Introduce \"Blue Bus\". $V_{blue} = V_{red}$ (perfect substitute).\n",
                "- MNL Prediction: $P(Car) = P(Red) = P(Blue) = 1/3$.\n",
                "- Reality: Bus share stays 0.5, split between Red and Blue. $P(Car)=0.5, P(Red)=0.25, P(Blue)=0.25$.\n",
                "\n",
                "MNL fails fundamentally here because it treats Blue Bus as a distinct, independent mode (like a train)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def logit_prob(V_array, beta=1.0):\n",
                "    # V_array: shape (N_alts,)\n",
                "    exp_v = np.exp(beta * np.array(V_array))\n",
                "    return exp_v / np.sum(exp_v)\n",
                "\n",
                "print(\"Scenario 1: Car vs Red Bus (Equal Utility)\")\n",
                "probs_1 = logit_prob([1.0, 1.0]) # [Car, Red Bus]\n",
                "print(f\"P(Car)={probs_1[0]:.2f}, P(Red)={probs_1[1]:.2f}\")\n",
                "\n",
                "print(\"\\nScenario 2: Car vs Red Bus vs Blue Bus (MNL Prediction)\")\n",
                "probs_2 = logit_prob([1.0, 1.0, 1.0]) # [Car, Red Bus, Blue Bus]\n",
                "print(f\"P(Car)={probs_2[0]:.2f}, P(Red)={probs_2[1]:.2f}, P(Blue)={probs_2[2]:.2f}\")\n",
                "print(\"-> Note: Car share drops from 50% to 33%. This is the IIA fallacy.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The Solution: Nested Logit (Renormalization)\n",
                "\n",
                "We group Red Bus and Blue Bus into a **Nest** called \"Bus\".\n",
                "\n",
                "**Step 1**: Calculate \"inclusive value\" (Logsum) of the nest.\n",
                "$$ I_{bus} = \\ln (e^{V_{red}} + e^{V_{blue}}) $$\n",
                "\n",
                "**Step 2**: Calculate upper level choice (Car vs Bus).\n",
                "$$ P_{bus} = \\frac{e^{\\mu I_{bus}}}{e^{V_{car}} + e^{\\mu I_{bus}}} $$\n",
                "Where $\\mu$ is a scale parameter ($0 < \\mu \\le 1$). If $\\mu=1$, it collapses back to MNL.\n",
                "\n",
                "**Physics Interpretation**: This is exactly **Coarse Graining (Renormalization)**. We trace out the micro-states (Red/Blue) and replace them with a single macro-state (Bus) with an effective free energy ($F_{eff} = -kT \\cdot I_{bus}$)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def nested_logit_prob(V_car, V_red, V_blue, mu=0.5):\n",
                "    # 1. Lower nest (Red, Blue)\n",
                "    # Inclusive Value (Logsum) of the nest\n",
                "    IV_bus = np.log(np.exp(V_red) + np.exp(V_blue))\n",
                "    \n",
                "    # 2. Upper level (Car, Bus_Nest)\n",
                "    # Utility of nest = mu * IV\n",
                "    V_upper = np.array([V_car, mu * IV_bus])\n",
                "    exp_V_upper = np.exp(V_upper)\n",
                "    probs_upper = exp_V_upper / np.sum(exp_V_upper) # [P_car, P_bus]\n",
                "    \n",
                "    # 3. Conditional probs inside nest\n",
                "    P_red_given_bus = np.exp(V_red) / (np.exp(V_red) + np.exp(V_blue))\n",
                "    P_blue_given_bus = np.exp(V_blue) / (np.exp(V_red) + np.exp(V_blue))\n",
                "    \n",
                "    # 4. Final probabilities\n",
                "    P_car = probs_upper[0]\n",
                "    P_red = probs_upper[1] * P_red_given_bus\n",
                "    P_blue = probs_upper[1] * P_blue_given_bus\n",
                "    \n",
                "    return P_car, P_red, P_blue\n",
                "\n",
                "print(\"\\nScenario 3: Nested Logit (mu=0.5)\")\n",
                "P_car, P_red, P_blue = nested_logit_prob(1.0, 1.0, 1.0, mu=0.5)\n",
                "print(f\"P(Car)={P_car:.2f}\")\n",
                "print(f\"P(Red)={P_red:.2f}\")\n",
                "print(f\"P(Blue)={P_blue:.2f}\")\n",
                "print(\"-> Success! Car share is preserved (approx 0.5), while bus share is split.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Consumer Surplus as Free Energy\n",
                "\n",
                "In economics, the **Consumer Surplus (CS)** is the expected maximum utility a person gets from the choice set.\n",
                "$$ CS = E[\\max_j (V_j + \\varepsilon_j)] $$\n",
                "\n",
                "Williams (1977) proved that for Logit (Gumbel noise), this has a closed form:\n",
                "$$ CS = \\frac{1}{\\beta} \\ln \\left( \\sum_j e^{\\beta V_j} \\right) + C $$\n",
                "\n",
                "Compare this to Helmholtz Free Energy:\n",
                "$$ F = -k_B T \\ln Z = -\\frac{1}{\\beta} \\ln \\left( \\sum_j e^{-\\beta E_j} \\right) $$\n",
                "\n",
                "Notice the sign flip ($V_j \\leftrightarrow -E_j$).\n",
                "\n",
                "**Physics Meaning**: We minimize Free Energy $F = U - TS$. \n",
                "**Economics Meaning**: We maximize Surplus $CS = \\text{Mean Utility} + \\text{Entropy Benefit}$.\n",
                "\n",
                "The term $\\ln \\sum e^{\\beta V_j}$ is not just a mathematical trick; it measures the **Value of Variety**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculating Value of Variety\n",
                "def calculate_cs(V_options, beta=1.0):\n",
                "    exp_sum = np.sum(np.exp(beta * np.array(V_options)))\n",
                "    return (1/beta) * np.log(exp_sum)\n",
                "\n",
                "cs_1_option = calculate_cs([1.0])\n",
                "cs_2_options = calculate_cs([1.0, 1.0])\n",
                "cs_3_options = calculate_cs([1.0, 1.0, 1.0])\n",
                "\n",
                "print(f\"Surplus (1 option): {cs_1_option:.4f}\")\n",
                "print(f\"Surplus (2 options): {cs_2_options:.4f}\")\n",
                "print(f\"Surplus (3 options): {cs_3_options:.4f}\")\n",
                "print(f\"Incremental benefit of 2nd option: {cs_2_options - cs_1_option:.4f} (Should beln(2) when beta=1)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}