---
type: concept
title: Shannon 熵与最大熵原则
tags: ['information', 'inference', 'M1']
prereq: []
source: ['Shannon / Jaynes']
status: ready
---

## 一句话
Shannon 熵衡量分布的“无知程度”；最大熵原则（MaxEnt）则是要求我们在给定已知约束下，选择那个排除掉所有无权假设、最“诚实”的概率分布。

## 从“度量无知”到“诚实推断”

在统计物理中，我们经常面临一个**不适定问题 (Ill-posed problem)**：已知系统的某些宏观平均值（如总能量、总人口），但微观态却有无穷多种可能。我们该如何给这些微观态分配概率？

E. T. Jaynes 在 1957 年给出了震聋发聩的回答：**概率论不是频率的统计，而是逻辑推断的延伸。**
如果我们选择一个熵值较小的分布，意味着我们无缘无故地引入了额外的“偏见”或“信息”；而唯一不引入任何额外假设、只保留已知约束的推断方式，就是最大化 Shannon 熵。

## Shannon 熵：信息的缺失量

Shannon 证明了，若要寻找一个函数 $H(p)$ 来度量分布 $p=\{p_1, \dots, p_n\}$ 的不确定性，且满足连续性、单调性和可加性，那么形式必然是：
\[
H(p) = -\sum_{i} p_i \ln p_i
\]
这里的负号确保了熵值为正。直觉上，当分布越平坦（均匀），$H$ 越大，说明我们越“无知”。

## 最大熵推断的推导 (Derivation)

假设我们已知系统的 $K$ 个宏观约束：
\[
\langle f_k \rangle = \sum_i p_i f_k(i) = c_k, \quad k=1, \dots, K
\]
以及归一化条件 $\sum_i p_i = 1$。为了找到最优分布 $p^*$，我们构造拉格朗日函数：
\[
\mathcal{L}(p, \lambda_0, \lambda_1, \dots, \lambda_K) = -\sum_i p_i \ln p_i - (\lambda_0 - 1) (\sum_i p_i - 1) - \sum_k \lambda_k (\sum_i p_i f_k(i) - c_k)
\]
对 $p_i$ 求偏导并令其为 0：
\[
\frac{\partial \mathcal{L}}{\partial p_i} = -(\ln p_i + 1) - (\lambda_0 - 1) - \sum_k \lambda_k f_k(i) = 0
\]
解得：
\[
\ln p_i = -\lambda_0 - \sum_k \lambda_k f_k(i) \implies p_i = \frac{1}{Z} \exp\left(-\sum_k \lambda_k f_k(i)\right)
\]
其中 $Z = e^{\lambda_0} = \sum_i \exp(-\sum_k \lambda_k f_k(i))$ 为**配分函数**。

**结论**：只要约束是线性的，最合理的推断结果必然是**指数族分布**。

## 深度直觉：拉格朗日乘子的“影子价格”视角

为什么我们要构造这么复杂的 $\mathcal{L}$？

1.  **自由与代价的权衡**：  
    把 Shannon 熵 $H$ 看作系统的“**自由度**”或“**选择权**”。如果没有约束，你肯定会选择均匀分布来获得最大自由。但现在外界强加了约束（比如平均能量必须是 $E$），这就像是让你买东西时必须付出的“**代价**”。
    
2.  **$\lambda$ 是“影子价格” (Shadow Price)**：  
    拉格朗日乘子 $\lambda_k$ 的物理意义其实是**转换率**。它衡量了：如果你稍微放松一点点约束（比如允许平均能量增加 $dE$），你的系统熵（自由度）能增加多少？
    在平衡点，你会发现增加概率带来的“边际自由度增长” ($\frac{\partial H}{\partial p_i}$) 恰好被为了维持约束而付出的“边际代价” ($\lambda \sum f_i$) 所抵消。

3.  **为什么导数是 $\ln p_i$？**  
    这非常关键。$p \ln p$ 的导数是 $1 + \ln p$。这意味着当你把一个微观态的概率 $p_i$ 从 0.001 增加到 0.002 时，熵的增量是非常大的；但如果你把 $p_i$ 从 0.5 增加到 0.501，熵的增量就很小。
    这产生了一种**“均贫富”的驱动力**：系统极度厌恶概率为 0 的状态。这种倾向与“惩罚高能态”的约束力在某一点达成平衡，那个平衡点就是指数函数。

## 城市映射：为什么重力模型无处不在？

在城市科学中，著名的**重力模型 (Gravity Model)** 其实就是 MaxEnt 的直接产物：
- 如果我们已知区域间的**总出行量**和**平均出行成本**（约束）；
- 那么在没有任何其他偏好假设下，区域间的出行概率 $T_{ij}$ 必然遵循指数形式 $T_{ij} \propto e^{-\beta c_{ij}}$。

这意味着重力模型之所以有效，并不是因为它模仿了物理界的万有引力，而是因为它恰好是处理“只知道平均成本”这一信息的**最保守、最不带偏见**的统计基线。

## 深度直觉
最大熵原则告诉我们：**自然界之所以呈现出 Boltzmann 分布，不仅是因为物理定律，更是因为逻辑上的必然。** 在给定能量期望的情况下，这种分布涵盖了最多的微观可能性。任何偏离这种分布的状态，其出现概率在统计学上都是极低的。
