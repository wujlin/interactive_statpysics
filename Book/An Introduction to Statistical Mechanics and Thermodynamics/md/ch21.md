# 21

# Refining the Definition of Entropy

$S = k\log W$

Inscription on Boltzmann's tombstone

(first written in this form by Max Planck in 1900)

In this section we will refine the definition of the entropy beyond that given in Part I. Specifically, we will be concerned with the distribution of the energy, which had been taken to be a delta function. This is not correct if the system of interest has ever been in contact with another macroscopic system. $^1$

# 21.1 The Canonical Entropy

In the canonical distribution, the energy distribution is given by eq. (19.17), which has a non-zero probability for all energies. Although this distribution is not exact for the interaction of a system with another finite system, it is a reasonable approximation and far better than a delta function. More importantly, the entropy calculated from it is a significant improvement for any macroscopic system that has been in contact with any other macroscopic system. We will denote this quantity as the canonical entropy.

# 21.1.1 The entropy of a system is independent of the size of the system with which it has exchanged energy

Consider three macroscopic systems labeled  $A, B$ , and  $C$ . Assume that systems  $A$  and  $B$  are the same size and composition, so that the entropies of systems  $A$  and  $B$  are equal by symmetry. All three systems are initially in equilibrium with each other.

Next, remove system  $C$  from thermal contact with the other two systems.  $A$  and  $B$  must still be in equilibrium with each other at the same temperature as before  $C$  was removed. They must also have the same average energy as they did when they were in contact with  $C$ .

The entropies must be unchanged. If the total entropy were to decrease, it would be a violation of the second law of thermodynamics (and the second essential postulate). If the entropy were to increase upon separation, then bringing system  $C$  back into thermal contact with systems  $A$  and  $B$  would decrease the entropy, which would also be a violation of the second law. The only possibility consistent with the second law is that the entropy is unchanged.

Note that the fluctuations of the energies in  $A$  and  $B$  are narrower when they are separated from the larger system  $C$ , but that this small change in the width has no effect on the entropy. Therefore, the entropy of an isolated system is correctly given by the canonical entropy.

It is impossible for thermodynamic measurements to determine the size of the system with which a given system has been in contact.

# 21.1.2 The calculation of the canonical entropy using a Massieu function

Massieu functions do not require the inversion of the fundamental relation  $S = S(U, V, N)$  to find  $U = U(S, V, N)$ , which will make them particularly useful when we consider quantum systems with a non-monotonic density of states. We will use a dimensionless entropy  $\tilde{S} = S / k_{B}$ , which was introduced in Section 12.6 along with the differential form of the fundamental relation in the  $\tilde{S}$ -representation,

$$
d \tilde {S} = \beta d U + (\beta P) d V - (\beta \mu) d N, \tag {21.1}
$$

where  $\beta = 1 / k_{B}T$ ,  $P$  is the pressure,  $V$  is the volume,  $\mu$  is the chemical potential, and  $N$  is the number of particles. From eq. (21.1) we immediately have

$$
\left(\frac {\partial \tilde {S}}{\partial U}\right) _ {V, N} = \beta . \tag {21.2}
$$

We will need the Massieu function  $\tilde{S}[\beta]$ ,

$$
\tilde {S} [ \beta ] = \tilde {S} - \beta U = - \beta (U - T S) = - \beta F, \tag {21.3}
$$

and the differential form of the fundamental relation in this representation,

$$
d \tilde {S} [ \beta ] = - U d \beta + (\beta P) d V - (\beta \mu) d N. \tag {21.4}
$$

Since

$$
\tilde {S} [ \beta ] = - \beta F = \ln Z (\beta , V, N), \tag {21.5}
$$

this enables us to calculate the Massieu function directly from the canonical partition function.

Given the Massieu function, we can obtain the energy  $U$  from

$$
\left(\frac {\partial \tilde {S} [ \beta ]}{\partial \beta}\right) _ {V, N} = - U. \tag {21.6}
$$

To obtain  $\tilde{S}$  from  $\tilde{S}[\beta]$ , use

$$
\tilde {S} = \tilde {S} [ \beta ] + \beta U, \tag {21.7}
$$

and substitute  $\beta = \beta (U)$

# 21.1.3 The canonical entropy of the classical ideal gas

To calculate the canonical and grand canonical forms of the entropy, the density of states of the classical ideal gas must first be evaluated as

$$
\Omega_ {C I G} (E, V, N) = \frac {\pi^ {3 N / 2}}{(3 N / 2 - 1) !} \frac {1}{h ^ {3 N} N !} V ^ {N} (2 m) ^ {3 N / 2} E ^ {3 N / 2 - 1}. \tag {21.8}
$$

This can be done by carrying out the integrals as shown in Chapters 4 and 6.

Finding the explicit expression for the canonical entropy involves a bit of algebra, which we will leave as a problem at the end of the chapter. The result is

$$
S _ {C} = k _ {B} \left[ N \left(\frac {3}{2}\right) \ln \left(\frac {U}{N}\right) + \ln \left(\frac {V ^ {N}}{N !}\right) + N \left(\frac {3}{2}\right) \ln \left(\frac {4 \pi m}{3 h ^ {2}}\right) + \frac {3 N}{2} \right]. \tag {21.9}
$$

Note that Eq. (21.9) uses  $U = \langle E \rangle$ . The factorials associated with the energy integral over the surface of a sphere in momentum space, appear in the Boltzmann entropy, but not in the canonical entropy. Only the term associated with the volume involves a factorial  $(1 / N!)$ .

# 21.2 The Grand Canonical Entropy

The microcanonical and canonical ensembles make the approximation that the value of  $N$  is specified exactly. This approximation is very good, but not quite correct if the system has ever exchanged particles with another system. The situation is the same as for the energy dependence, and it results in a small error in the predictions of the entropy.

For the classical ideal gas, this error leads to an expression for the entropy that is not exactly extensive. Systems with short-range interactions, such as those shown schematically in Fig. 7.1, are expected to have small deviations from extensivity that

only go to zero as  $N$  goes to infinity. However, the classical ideal gas is a model that has no interactions between particles. Every particle is expected to contribute separately to the macroscopic properties of the system. The small deviations from extensivity are surprising from this point of view.

The resolution is to include the width of the  $N$ -distribution in the calculation of the entropy. This leads us to the grand canonical distribution as providing an approximation to the true  $N$ -distribution. The same kind of argument that we used in Section 21.1.1 to justify the canonical distribution also applies here.

For the grand canonical ensemble, we will use  $\tilde{S}[\beta, (\beta \mu)]$  to derive the grand canonical entropy. As earlier, parentheses around the second variable indicate that the product of  $\beta$  and  $\mu$  is treated as a single variable.

The Legendre transform of  $\tilde{S}$  with respect to both  $\beta$  and  $(\beta \mu)$  uses the equation

$$
- (\beta \mu) = \left(\frac {\partial \tilde {S}}{\partial N}\right) _ {U, N} \tag {21.10}
$$

in addition to eq. (21.2).

The Legendre transform of  $\tilde{S}$  with respect to both  $\beta$  and  $(\beta \mu)$  is then given by the Massieu function

$$
\tilde {S} [ \beta , (\beta \mu) ] = \tilde {S} - \beta U + (\beta \mu) N, \tag {21.11}
$$

so that

$$
\tilde {S} [ \beta , (\beta \mu) ] = \ln \mathcal {Z} (\beta , V, (\beta \mu)), \tag {21.12}
$$

where  $\mathcal{Z}$  is the grand canonical partition function.

The differential of the Massieu function  $\tilde{S}[\beta, (\beta \mu)]$  is

$$
d \tilde {S} [ \beta , (\beta \mu) ] = - U d \beta + (\beta P) d V + N d (\beta \mu). \tag {21.13}
$$

This immediately gives

$$
\left(\frac {\partial \tilde {S} [ \beta , (\beta \mu) ]}{\partial \beta}\right) _ {V, (\beta \mu)} = - U, \tag {21.14}
$$

and

$$
\left(\frac {\tilde {S} [ \beta , (\beta \mu) ]}{\partial (\beta \mu)}\right) _ {\beta , V} = N. \tag {21.15}
$$

To obtain  $\tilde{S}$  from  $\tilde{S}[\beta, (\beta \mu)]$ , use

$$
\tilde {S} = \tilde {S} [ \beta , (\beta \mu) ] + \beta U - (\beta \mu) N, \tag {21.16}
$$

and replace the  $\beta$  and  $(\beta \mu)$  dependence by  $U$  and  $\langle N\rangle$

The calculation involves some algebra, which we have left to a problem at the end of the chapter. The answer is

$$
S _ {G C} = \langle N \rangle k _ {B} \left[ \frac {3}{2} \ln \left(\frac {U}{\langle N \rangle}\right) + \ln \left(\frac {V}{\langle N \rangle}\right) + \ln \left(\frac {4 \pi m}{3 h ^ {2}}\right) ^ {3 / 2} + \frac {5}{2} \right]. \tag {21.17}
$$

This expression for the grand canonical entropy of a classical ideal gas is exactly extensive, and no use has been made of Stirling's approximation.

# 21.3 Problems

# PROBLEM 21.1

# The canonical entropy.

A different view of the entropy of the ideal gas.

Consider a classical ideal gas of  $N$  particles in three dimensions. The particles are contained in a box of volume  $V$ . Denote the dimensionless entropy by  $\tilde{S} = S / k_{B}$ . Do not use Stirling's approximation.

1. Write the partition function.  
2. Evaluate the partition function in closed form.  
3. Denote the Legendre transform of the dimensionless entropy with respect to  $\beta$  as  $\tilde{S}[\beta]$ . Evaluate  $\tilde{S}[\beta]$ .  
4. Do an inverse Legendre transform of  $\tilde{S}[\beta]$  to find  $\tilde{S}$ .  
5. Find  $S$

# PROBLEM 21.2

# The grand canonical entropy.

A different view of the entropy of the ideal gas.

Consider a classical ideal gas of  $N$  particles in three dimensions. The particles are contained in a box of volume  $V$ . Denote the dimensionless entropy by  $\tilde{S} = S / k_{B}$ . Do not use Stirling's approximation.

1. Calculate the grand canonical partition function for the classical ideal gas. You can use the results of the previous assignment in your solution.  
2. Denote the Legendre transform of the dimensionless entropy with respect to  $\beta$  and  $(\beta \mu)$  as  $\bar{S} [\beta ,(\beta \mu)]$

Evaluate  $S[\beta, (\beta \mu)]$ .

3. Do an inverse Legendre transform of  $\tilde{S}[\beta, (\beta \mu)]$  to find  $\tilde{S}$ .  
4. Find  $S$