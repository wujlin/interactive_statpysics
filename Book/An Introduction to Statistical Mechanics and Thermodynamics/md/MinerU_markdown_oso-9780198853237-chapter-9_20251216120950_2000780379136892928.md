# The Postulates and Laws of Thermodynamics

In this house, we OBEY the laws of thermodynamics!

Homer Simpson (Dan Castellaneta, American actor, and writer)

# 9.1 Thermal Physics

With this chapter we begin the formal study of thermodynamics, based on the properties of the entropy developed in Part 1 from the study of the foundations of classical statistical mechanics. We will return to statistical mechanics in Parts III and IV.

The theories of statistical mechanics and thermodynamics deal with the same physical phenomena. In many cases it is possible to derive exactly the same equations from either theory, although not necessarily with equal ease. In no case do the two theories contradict each other. Nevertheless, they do have different origins, and are based on very different assumptions. Because of the different points of view that accompanied the development of thermodynamics and statistical mechanics, it is easy to become confused about what is an assumption and what is a derived result.

The task of keeping assumptions and results straight is made more difficult by the traditional description of thermodynamic ideas by the terms 'postulates' and 'laws', since a postulate or law in thermodynamics might also be regarded as being derived from statistical mechanics.

# 9.1.1 Viewpoint: Statistical Mechanics

The foundations of statistical mechanics lie in the assumption that atoms and molecules exist and obey the laws of either classical or quantum mechanics. Since macroscopic measurements on thermal systems do not provide detailed information on the positions and momenta (or the many-particle wave function in quantum mechanics) of the  $10^{20}$  or more atoms in a typical object, we must also use probability theory and make assumptions about a probability distribution in a many-dimensional space.

On the basis of the assumptions of statistical mechanics, we can write down a formal expression for the entropy as the logarithm of the probability of a composite system,

as we did for classical statistical mechanics in Part I. In some simple cases, such as the classical ideal gas, we can even obtain a closed form expression for the entropy. In most cases we must make approximations.

In Part I, we found an explicit expression for the entropy of the classical ideal gas, which allows us to understand the properties of the entropy for this simple system. We also presented arguments that certain properties of the entropy should not change when interactions between particles are included in the calculation.

The point of view taken in this book is that statistical mechanics is the more fundamental theory. Thermodynamics is based on assumptions that can be understood in the context of statistical mechanics. What we will call the 'Postulates of Thermodynamics' and the 'Laws of Thermodynamics' are, if not theorems, at least plausible consequences of the theory of statistical mechanics.

Molecular theory and statistical mechanics provide a fundamental explanation and justification of thermodynamics. We might as well take advantage of them.

# 9.1.2 Viewpoint: Thermodynamics

Thermodynamics was defined in Chapter 1 as the study of everything connected with heat. The field was developed in the nineteenth century before the existence of atoms and molecules was accepted by most scientists. In fact, the thermodynamics of the nineteenth century was expressed in terms of the mass of a system, rather than the number of particles it contains, which is standard today.

Because thermodynamics was developed without benefit of the insight provided by molecular theory, its history is characterized by ingenious but rather convoluted arguments. These arguments eventually led Herbert Callen (American physicist, 1919-1993) and his advisor, László Tiszra (Hungarian and American physicist, 1907-2009), to create a formal system of postulates based on the concept of entropy, from which all of thermodynamics could be derived.

From the point of view of thermodynamics, everything starts with the postulates presented later in this chapter. Even though these postulates can be traced back to statistical mechanics, they provide a reliable starting place for a self-consistent theory that produces complete agreement with experiments in the real world.

Thermodynamics can also be regarded as complementary to statistical mechanics. It gives different insights into physical properties. In many cases, thermodynamics is actually more efficient than statistical mechanics for deriving important equations.

Beginning the study of thermodynamics with the formal postulates, as we do in Part II of this book, avoids much of the complexity that nineteenth-century scientists had to deal with. The only drawback of the formal postulates is that they are rather abstract. A major purpose of Part I of this book was to make them less abstract by providing an explicit example of what entropy means and how it might be calculated.

In this chapter, we will make the connection between the statistical mechanics of Part I and the thermodynamics of Part II more explicit by discussing the concepts of 'state'

and 'state function' in the two theories. We will then present the postulates and laws of thermodynamics, including references to the corresponding results from classical statistical mechanics that were obtained in Part I.

# 9.2 Microscopic and Macroscopic States

A microscopic state is a property of a system of particles. In classical mechanics, a microscopic state is characterized by specific values of the positions and momenta of every particle; that is, a point in phase space. In quantum mechanics, a microscopic state is characterized by a unique, many-particle wave function.

In thermodynamic experiments we restrict ourselves to 'macroscopic' measurements, which are characterized by their limited resolution; by definition, macroscopic measurements cannot resolve individual particles or microscopic length scales. It might be appropriate to remember that thermodynamics was developed before scientists even believed that molecules existed—and they certainly did not measure the behavior of individual molecules.

For both classical and quantum systems, the microscopic state is not experimentally accessible to macroscopic measurements. In the experiments we wish to describe, we can obtain some information about the microscopic state, but we cannot determine it completely.

A macroscopic state is not a property of a thermodynamic system; it is a description of a thermodynamic system based on macroscopic measurements. Due to the experimental uncertainty of macroscopic measurements, a macroscopic state is consistent with an infinity of microscopic states. A system can be in any microscopic state that would be consistent with the experimental observations.

Formally, this might seem to be a rather loose definition of what we mean by 'macroscopic state'. In practice, however, there is rarely a problem. Because microscopic fluctuations are so much smaller than experimental uncertainties, it is relatively easy to specify which microscopic states are consistent with macroscopic measurements.

# 9.3 Macroscopic Equilibrium States

An equilibrium state is a special kind of macroscopic state. Within the limits of experimental measurements, the properties of a system in an equilibrium state do not change with time, and there is no net transfer of energy or particles into or out of the system.

Equilibrium states can usually be described by a small number of measurements in the sense that all other properties are completely determined within experimental error. In the case of an ideal gas, discussed in Part I, we need to know only the number of particles, the volume, and the energy. Given those values, we can calculate the temperature, pressure, and chemical potential, along with a number of other quantities that we will discuss in the following chapters.

For more complicated systems we might need to know how many molecules of each type are present, and perhaps something about the shape and surface properties of the container. In all cases, the number of quantities needed to characterize an equilibrium system will be tiny in comparison with the number of particles in the system.

# 9.4 State Functions

The term 'state function' denotes any quantity that is a function of only the small number of variables needed to specify an equilibrium state.

The main substance of the thermodynamic postulates is that for every macroscopic system in thermal equilibrium there exists a state function called the entropy, which has certain properties listed in Section 9.5. Given these postulates, the entire mathematical structure of thermodynamics can be derived—which is the subject of the rest of Part II.

# 9.5 Properties and Descriptions

In order to understand thermodynamics it will be important to keep in mind the distinction between a property of a system and a description of a system. A 'property' is an exact characteristic of a system. If a system contains exactly 63749067496584764830091 particles, that is a property of the system. A 'description' is, at most, an estimate of a property. If measurements reveal that a system has  $6.374907(2) \times 10^{23}$  particles, that is a description.

In Chapter 4 we calculated the average number of particles in a subsystem. That number is an excellent description of the system for human purposes because the relative statistical fluctuations are so small. However, it is not the true number of particles at any instant of time. In a system of  $10^{20}$  particles. The true number of particles is a property of the system, but its exact value will fluctuate over time by roughly  $10^{10}$  particles.

Because thermodynamics deals with descriptions of macroscopic systems, rather than their true properties, we will not belabor the distinction in Part II. All quantities will be descriptions of a system.

# 9.6 The Essential Postulates of Thermodynamics

I will present the postulates of thermodynamics in a somewhat different form than originally given by Callen. They will be separated into essential postulates, which must always be true, and optional postulates, which will not apply to every thermodynamic system, but which are very convenient when they do apply.

These four postulates must always be true for a complete theory of thermodynamics for general systems.

# 9.6.1 Postulate 1: Equilibrium States

Postulate 1: There exist equilibrium states of a macroscopic system that are characterized uniquely by a small number of extensive variables.

Recall that extensive variables are quantities that provide a measure of the size of the system. Examples include the total energy, the volume, and the number of particles. By contrast, intensive parameters are quantities that are independent of the size of the system. Examples include temperature, pressure, and chemical potential.

The remaining postulates all specify properties of a state function called the 'entropy'. These properties should be compared to what you know of the entropy of an ideal gas from Part I.

# 9.6.2 Postulate 2: Entropy Maximization

Postulate 2: The values assumed by the extensive parameters of an isolated composite system in the absence of an internal constraint are those that maximize the entropy over the set of all constrained macroscopic states.

The property of the entropy in the second postulate is by far the most important. It has two consequences that we will use repeatedly.

First, whenever we release a constraint on a composite system, the entropy will not decrease,

$$
\Delta S \geq 0. \tag {9.1}
$$

This follows directly from Boltzmann's idea that macroscopic systems go from less probable states to more probable states. The final state must be the most probable state and therefore have the highest entropy. This property is the Second Law of Thermodynamics.

Eq. (9.1) can be rather puzzling. It gives time a direction, sometimes called the 'arrow of time'. This can seem strange, since the underlying equations of motion for the molecules, either classical or quantum, are time-reversal invariant. There is not really a contradiction, and we will reconcile the apparent conflict in Chapter 22.

The second consequence of eq. (9.1) is that we can find the equilibrium values of the extensive parameters describing the amount of something in each (sub)system after a constraint has been released by maximizing the entropy. This will provide an effective approach to solving problems in thermodynamics.

# 9.6.3 Postulate 3: Additivity

Postulate 3: The entropy of a composite system is additive over the constituent subsystems.

Additivity means that

$$
S _ {j, k} \left(E _ {j}, V _ {j}, N _ {j}; E _ {k}, V _ {k}, N _ {k}\right) = S _ {j} \left(E _ {j}, V _ {j}, N _ {j}\right) + S _ {k} \left(E _ {k}, V _ {k}, N _ {k}\right), \tag {9.2}
$$

where  $S_{j}$  and  $S_{k}$  are the entropies of systems  $j$  and  $k$ .

Since we regard the composite system as fundamental in the definition of entropy, and the entropy of a composite system separates into the sum of the entropies of the subsystems, this postulate could be equally well called the postulate of separability. The term 'additivity' is generally preferred because of the concentration on the properties of simple systems in the history of thermodynamics.

Most interactions between molecules are short ranged. If we exclude gravitational interactions and electrical interactions involving unbalanced charges, the direct interaction between any two molecules is essentially negligible at distances of more than a few nanometers. As discussed at the end of Chapter 7, this leads to an approximate separation of the integrals defining the entropy for the subsystems, so that the entropy of the composite system is just the sum of the entropies of the subsystem.

Additivity for systems with interacting particles is an approximation in that it neglects direct interactions between particles in different subsystems (see the discussion in Section 7.6.2). However, deviations from additivity are usually very small due to the extremely short range of intermolecular interactions in comparison to the size of macroscopic systems.

# 9.6.4 Postulate 4: Continuity and Differentiability

Postulate 4: The entropy is a continuous and differentiable function of the extensive parameters.

The true number of particles is, of course, an integer. However, when we talk about the 'number of particles' or the value of  $N$ , we really mean a description of the number of particles that differs from the true number by less than the accuracy of our measurements. Since  $N$  is a description of the number of particles, it is not limited to being an integer.

Thermodynamics is much easier if we can work with functions that are continuous and differentiable. Conveniently, it is almost always true that we can.

This postulate is often given in terms of the assumed analyticity of the functions. However, the postulate of analyticity can break down. When it does, it usually signals some sort of instability or phase transition, which is particularly interesting. Stability and phase transitions are discussed in Chapters 16 and 17. We will consider specific examples of phase transitions in Chapters 28 and 31.

# 9.7 Optional Postulates of Thermodynamics

The following three postulates are not applicable to all thermodynamic systems. When they are applicable, they often simplify the analysis of thermodynamic behavior.

# 9.7.1 Optional Postulate 5: Extensivity

Postulate 5: The entropy is an extensive function of the extensive variables.

'Extensivity' is the property that the entropy is directly proportional to the size of the system; if the extensive parameters are all multiplied by some positive number  $\lambda$ , the entropy will be too,

$$
S (\lambda U, \lambda V, \lambda N) = \lambda S (U, V, N). \tag {9.3}
$$

Mathematically, eq. (9.3) means that the entropy is assumed to be an homogeneous, first-order function of the extensive variables.

The extensivity postulate is not true for all systems!

Even such a common system as a gas in a container violates this postulate, because the molecules of the gas can be adsorbed onto the inner walls of the container. Since the surface-to-volume ratio varies with the size of the container, the fraction of molecules adsorbed on the inner walls also varies, and such a system is not extensive.

For most of the book we will not assume extensivity, although in Chapter 13 we will see that extensivity can be extremely useful for investigating the properties of materials.

The properties of additivity and extensivity are often confused. This is probably due to the fact that many textbooks restrict their discussion of thermodynamics to homogeneous systems, for which both properties are true. Additivity is the more fundamental property. It is true whenever the range of interactions between particles is small compared to the size of the system. Extensivity is only true to the extent that the surface of the system and the interface with its container can be neglected.

# 9.7.2 Optional Postulate 6: Monotonicity

Postulate 6: The entropy is a monotonically increasing function of the energy for equilibrium values of the energy.

In the example we discussed in Part I, the entropy of the classical ideal gas was shown to be a monotonically increasing function of the energy. This monotonicity is important, since it implies that the temperature is positive, as we have shown in Chapter 8 for the ideal gas. However, monotonicity is not true for some of the most important models in physics, as we will see in Chapter 31. These models exhibit negative temperatures in some energy regions.

The question of whether the temperature of certain thermodynamic systems can be negative has become a topic of some debate in recent years. I have gone on record as saying that negative temperatures are consistent with thermodynamics, and I will

develop the formalism of thermodynamics accordingly. What I say about positive temperatures is not controversial. What I say about negative temperatures is controversial.

There are a number of models of great importance to statistical mechanics, for which  $\partial S / \partial U = 1 / T < 0$  in certain energy regions (see Chapter 31). For these models, Postulate 6 does not hold. On the other hand, this is not the usual case. Consequently, many of the applications of thermodynamics, like the theory of heat engines, assume that  $T > 0$ . These will be discussed in Chapter 11, which will include a brief section on the changes required for negative temperatures.

# 9.7.3 Optional Postulate 7: The Nernst Postulate

Postulate 7: The entropy of any system is non-negative.

The Nernst Postulate<sup>2</sup> is also known as the Third Law of Thermodynamics, adding to the confusion between laws and postulates. It only applies to quantum systems, but, since all real systems are quantum mechanical, it ultimately applies to everything. It has some important consequences, which are discussed in Chapter 18. The Nernst Postulate is listed as optional because classical systems are interesting in themselves and useful in providing a contrast with the special properties of quantum systems.

The Third Law is the only law (or postulate) that cannot be understood on the basis of classical statistical mechanics. For classical models, the entropy always goes to negative infinity as the temperature goes to zero. The explanation of the Third Law is intrinsically quantum mechanical. Its consequences will be discussed in Chapter 18, but it will not be derived until Chapter 23 in Part IV.

In quantum statistical mechanics there is a universally recognized convention for the absolute value of the entropy that will be discussed in Part IV. This convention implies that

$$
\lim  _ {T \rightarrow 0} S (T) \geq 0. \tag {9.4}
$$

The Third Law (or Nernst Postulate) is often stated as  $\lim_{T\to 0}S(T) = 0$ , but that is incorrect. There are many examples of systems with disordered ground states that have a (positive) non-zero entropy at zero temperature.

The Nernst Postulate is also often credited with preventing the attainment of a temperature of absolute zero, but that is also incorrect; absolute zero would still be unattainable if the world obeyed classical statistical mechanics.

# 9.8 The Laws of Thermodynamics

The 'laws' of thermodynamics were discovered considerably earlier than the formulation of thermodynamics in terms of 'postulates'. The peculiar numbering of the laws is due to fixing the First and Second laws before the importance of the 'zeroth' law was realized. The current numbering scheme was suggested by Ralph H. Fowler (British physicist and astronomer, 1889-1944) as a way of acknowledging the importance of the 'zeroth' law.

The laws of thermodynamics are:

Zeroth Law If two systems are each in equilibrium with a third system, they are also in equilibrium with each other.

First Law Heat is a form of energy, and energy is conserved.

Second Law After the release of a constraint in a closed system, the entropy of the system never decreases.

Third Law (Nernst Postulate) The entropy of any quantum mechanical system goes to a constant as the temperature goes to zero.

The Zeroth Law was derived from statistical mechanics in Section 7.9.

The First Law is simply conservation of energy. However, at the time it was formulated it had just been discovered that heat was a form of energy, rather than some sort of mysterious fluid as had been previously supposed.

The Second Law is essentially the same as Postulate 2 in Subsection 9.6.2.

The Third Law is listed as Postulate 7 in Section 9.7.3.