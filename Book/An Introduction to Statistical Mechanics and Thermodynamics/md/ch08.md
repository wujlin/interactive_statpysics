# Temperature, Pressure, Chemical Potential, and All That

The most simple test of the equality of temperature of two bodies is that they remain in equilibrium when brought into thermal contact.

J. Willard Gibbs

In this chapter we will discuss the temperature,  $T$ , the pressure,  $P$ , and the chemical potential,  $\mu$ . We will find explicit expressions for these three quantities in terms of partial derivatives of the entropy with respect to energy, volume, and number of particles. In doing so, we will complete the foundations of classical statistical mechanics.

In Chapter 9, which begins Part II, we will see how the structure of statistical mechanics leads to a set of postulates that provides a foundation for thermodynamics. The rest of the chapters in Part II develop the theory of thermodynamics from these postulates.

In Part III we shall return to classical statistical mechanics. While the equations developed in Part I are (in my opinion) the clearest way to understand the assumptions of statistical mechanics, the new methods developed in Part III are much more powerful for practical calculations.

# 8.1 Thermal Equilibrium

We have seen in Section 7.9 that if two objects are in thermal equilibrium with each other (equilibrium with respect to energy exchange), then the partial derivative of the entropy with respect to energy must have the same value in both systems. We also know that if two systems are in thermal equilibrium, they must be at the same temperature. Therefore, the partial derivative of the entropy with respect to energy must be a unique function of temperature. One purpose of this chapter is to determine the nature of that function.

After we have determined the relationship between the temperature and the partial derivative of the entropy with respect to energy, we will find similar relationships between other partial derivatives of the entropy and the pressure and the chemical potential.

In all cases, the relationships linking  $T$ ,  $P$ , and  $\mu$  with partial derivatives of the entropy will be valid for all systems. This is a very powerful statement. It means that if we can calculate the entropy as a function of  $E$ ,  $V$ , and  $N$ , we can calculate all thermal properties of the system. For this reason, the entropy as a function of energy, volume, and number of particles,

$$
S = S (E, V, N), \tag {8.1}
$$

is known as a 'fundamental relation'. We will see later that there are a number of other functions that also contain the same, complete thermodynamic information about a system, which makes them equivalent to eq. (8.1). Such functions are also representations of the fundamental relation.

# 8.2 What do we Mean by 'Temperature'?

For most of us, temperature is the reading we obtain from a thermometer. The basic property of a thermometer is that it undergoes some sort of physical change that can be measured when it is heated or cooled. The most readily available thermometer is our own body. It shivers when it is cold, and sweats when it is hot. These are subjective measures, but they do form the basis for our intuitive understanding of temperature.

To make the definition of temperature objective, we need to choose something that will provide a theoretical and experimental standard, as well as a numerical scale. We will use the ideal gas for this purpose. Since we can calculate all of the properties of an ideal gas, we can determine how its volume or pressure will change when it is heated or cooled. Since we can do experiments on real dilute gases, we can relate our definition of temperature to the real world.

The basic equation we will use to uniquely define the thermodynamic temperature is the ideal gas law:

$$
P V = N k _ {B} T. \tag {8.2}
$$

The pressure  $P$  in this equation is defined as the average force per unit area. The constant  $k_{B}$  is called Boltzmann's constant. It has units of Joules per degree, and relates the temperature scale to the energy scale. Eq. (8.2) is often written as

$$
P V = n R T \tag {8.3}
$$

where  $n = N / N_{A}$  is the number of moles ( $N_{A} = 6.0221415 \times 10^{23}$  being Avogadro's number, named after Amedeo Carlo Avogadro, Count of Quaregna and Cerreto, Italian scientist, 1776-1856), and  $R = N_{A}k_{B}$  is known as the ideal gas constant. The experimental identification of the temperature as being proportional to the pressure for fixed volume, or the volume for fixed pressure, coincides with our notion that gas expands, or its pressure increases, when heated.

Although the ideal gas law is well known experimentally, to make contact with the entropy we must derive it from the properties of the ideal gas found in previous sections. What we will actually do in the next section is prove that the ratio  $PV / N$  is equal to a certain property of a thermal reservoir, and then use eq. (8.2) to associate that property with the temperature. This derivation will give us the universal relationship between the temperature and  $\partial S / \partial E$ .

# 8.3 Derivation of the Ideal Gas Law

The first step in the derivation of the ideal gas law is to derive the Maxwell-Boltzmann equation for the probability density of the momentum of one ideal gas particle. We will then use this probability density to determine the pressure due to collisions on the walls containing an ideal gas. This will lead us to the ideal gas law and the definition of the temperature in terms of the partial derivative of the entropy with respect to the energy.

# 8.3.1 The Maxwell-Boltzmann Equation

We are interested in the properties of a single particle in an ideal gas, and it does not matter which particle we choose, since they all have the same probability density. We can find that probability density as a marginal density of the full probability density in phase space. If the total energy of the system is  $E$ , the full probability density is given by

$$
P (p, q) = \frac {1}{\Omega (E , V , N)} \frac {1}{h ^ {3 N} N !} \delta (E - H (p, q)) \tag {8.4}
$$

where

$$
\Omega (E, V, N) = \frac {1}{h ^ {3 N} N !} \int d p \int d q \delta (E - H (p, q)) \tag {8.5}
$$

and we have used the compact notation  $p = \{\vec{p}_i | i = 1, 2, \ldots, N\}$  and  $q = \{\vec{r}_i | i = 1, 2, \ldots, N\}$ .

As a first step, we will find the marginal probability density for both the momentum and position of particle 1 by integrating  $P(p,q)$  in eq. (8.4) over all variables except  $\vec{p}_1$  and  $\vec{r}_1$ :

$$
\begin{array}{l} P (\vec {p} _ {1}, \vec {r} _ {1}) = \int d ^ {3} p _ {2} \dots d ^ {3} p _ {N} \int d ^ {3} r _ {2} \dots d ^ {3} r _ {N} P (p, q) \\ = \frac {1}{\Omega (E , V , N)} \frac {1}{h ^ {3 N} N !} \int d ^ {3} p _ {2} \dots d ^ {3} p _ {N} \int d ^ {3} r _ {2} \dots d ^ {3} r _ {N} \delta (E - H _ {N} (p, q)). \tag {8.6} \\ \end{array}
$$

In eq. (8.6),  $H_{N}$  is the Hamiltonian of the  $N$ -particle system.

We can write the integral in eq. (8.6) in terms of the function  $\Omega$  for a system with  $N - 1$  particles,

$$
\begin{array}{l} \Omega \left(E - | \vec {p} _ {1} | ^ {2} / 2 m, V, N - 1\right) = \frac {1}{h ^ {3 (N - 1)} (N - 1) !} \int d p _ {2} \dots d p _ {3 N} \\ \times \int d ^ {3} r _ {2} \dots d ^ {3} r _ {N} \delta \left(E - | \vec {p} _ {1} | ^ {2} / 2 m - \sum_ {i = 2} ^ {3 N} p _ {i} ^ {2} / 2 m\right). \tag {8.7} \\ \end{array}
$$

Note that the energy term,  $|\vec{p}_1|^2 / 2m$ , has been separated from the rest of the Hamiltonian because it has not been integrated out. With this notation, eq. (8.6) can be written compactly,

$$
P \left(\vec {p} _ {1}, \vec {r} _ {1}\right) = \frac {\Omega \left(E - | \vec {p} _ {1} | ^ {2} / 2 m , V , N - 1\right)}{N h ^ {3} \Omega (E , V , N)}. \tag {8.8}
$$

Since  $P(\vec{p}_1,\vec{r}_1)$  does not depend explicitly on  $\vec{r}_1$ , we can easily integrate  $\vec{r}_1$  out to obtain

$$
P (\vec {p} _ {1}) = \frac {V}{N h ^ {3}} \frac {\Omega (E - | \vec {p} _ {1} | ^ {2} / 2 m , V , N - 1)}{\Omega (E , V , N)}. \tag {8.9}
$$

We would like to take advantage of the fact that  $|\vec{p}_1|^2 / 2m$  is very small in comparison to  $E$ . We can exploit this by taking the logarithm of eq. (8.9), treating  $|\vec{p}_1|^2 / 2m$  as a small perturbation, and keeping only the leading terms:

$$
\begin{array}{l} \ln P \left(\vec {p} _ {1}\right) = \ln \Omega \left(E - \left| \vec {p} _ {1} \right| ^ {2} / 2 m, V, N - 1\right) \\ - \ln \Omega (E, V, N) + \ln \left(\frac {V}{N h ^ {3}}\right) \\ \approx \ln \Omega (E, V, N - 1) - \frac {| \vec {p} _ {1} | ^ {2}}{2 m} \frac {\partial}{\partial E} \ln \Omega (E, V, N - 1) \\ - \ln \Omega (E, V, N) + \ln \left(\frac {V}{N h ^ {3}}\right). \tag {8.10} \\ \end{array}
$$

The higher-order terms in the expansion are extremely small because the average value of  $|\vec{p}_1|^2 / 2m$  is on the order of a factor of  $N$  smaller than  $E$ .

The first thing to note about eq. (8.10) is that only the second term depends on  $\vec{p}_1$ .

The second thing to note about eq. (8.10) is that the approximation

$$
\frac {\partial}{\partial E} \ln \Omega (E, V, N - 1) \approx \frac {\partial}{\partial E} \ln \Omega (E, V, N) \tag {8.11}
$$

is extremely good. The error is only of order  $1 / N$ .

The derivative of  $\ln \Omega$  with respect to energy turns out to be so important that it has been universally assigned the Greek letter  $\beta$ ,

$$
\beta \equiv \frac {\partial}{\partial E} \ln \Omega (E, V, N). \tag {8.12}
$$

We can now rewrite eq. (8.10) in a much simpler form,

$$
\ln P \left(\vec {p} _ {1}\right) = - \beta \left| \vec {p} _ {1} \right| ^ {2} / 2 m + \text {c o n s t a n t s}, \tag {8.13}
$$

where the 'constants' may depend on  $E$ ,  $V$ , and  $N$ , but are independent of  $\vec{p}_1$ . Since the constants in this equation are determined by the normalization condition, we can complete the derivation of  $P(\vec{p}_1)$  from our knowledge of the properties of Gaussian integrals:

$$
P \left(\vec {p} _ {1}\right) = \left(\frac {\beta}{2 \pi m}\right) ^ {3 / 2} \exp \left(- \beta \frac {\left| \vec {p} _ {1} \right| ^ {2}}{2 m}\right). \tag {8.14}
$$

This is the Maxwell-Boltzmann probability density for the momentum of a single particle.

The expansion used in deriving  $P(\vec{p}_1)$  is extremely valuable in statistical mechanics. This is the first time it appears in this book, but far from the last.

Note that the three components of the momentum are independent, so that the probability density of a single component can be found easily by integrating out the other two,

$$
P \left(p _ {1, x}\right) = \sqrt {\frac {\beta}{2 \pi m}} \exp \left(- \beta \frac {p _ {1 , x} ^ {2}}{2 m}\right). \tag {8.15}
$$

# 8.3.2 The Pressure in an Ideal Gas

From the Maxwell-Boltzmann probability density for the momenta, we can calculate the pressure by integrating over the collisions that occur during a time  $\Delta t$ .

Consider a flat portion of the wall of the container of an ideal gas with area  $A$ . (The assumption of flatness is not necessary, but it makes the derivation much easier.) Define a coordinate system such that the  $x$ -axis is perpendicular to the wall. To simplify the problem, note that the  $y$ - and  $z$ -components of a particle's momentum do not change during a collision with the wall, so that they do not transfer any momentum to the wall and do not affect the pressure. This reduces the calculation to a one-dimensional problem.

By Newton's Second Law, the average force on the wall during a time-period  $\Delta t$  is given by the total momentum transferred to the wall during that period,

$$
F \Delta t = \int_ {\text {c o l l i s i o n s}} \Delta p _ {x} P \left(p _ {x}, \Delta t\right) d p _ {x}. \tag {8.16}
$$

$P(p_{x},\Delta t)$  is the probability of a particle hitting the wall during the time  $\Delta t$ , and the integral goes over all particles that hit the wall during that period of time. Since we intend to make  $\Delta t$  small, we do not have to include particles that might hit the wall a second time after bouncing off a different part of the container.

Let the wall be located at  $x = 0$ , with the particles confined to  $x < 0$ . Then particles will hit the wall only if  $p_x > 0$  and the particles are within a distance  $\Delta tv_x = \Delta tp_x / m$  of the wall, where  $m$  is the mass of a particle. Letting the area of the wall be denoted by  $A$ , the volume of particles that will hit the wall is  $A\Delta tp_x / m$ . The average number of particles in that volume is  $NA\Delta tp_x / Vm$ , where  $N$  is the total number of particles, and  $V$  is the total volume. If we multiply the number of particles in the volume by  $P(p_x)$  (the probability density of the momentum from eq. (8.14)), then multiply that by the momentum transfer,  $\Delta p_x = 2p_x$ , and finally integrate over the momentum, we have the total momentum transfer to the wall during  $\Delta t$ , which is equal to the average force times  $\Delta t$ :

$$
F \Delta t = \int_ {0} ^ {\infty} \sqrt {\frac {\beta}{2 \pi m}} \exp \left(- \beta \frac {p _ {x} ^ {2}}{2 m}\right) 2 p _ {x} \frac {N A \Delta t p _ {x}}{V m} d p _ {x}. \tag {8.17}
$$

Note that the integral extends only over positive momenta; particles with negative momenta are moving away from the wall.

Using the definition of the pressure as the force per unit area,  $P = F / A$ , eq. (8.17) becomes an equation for the pressure

$$
P = \frac {2 N}{V m} \sqrt {\frac {\beta}{2 \pi m}} \int_ {0} ^ {\infty} \exp \left(- \beta \frac {p _ {x} ^ {2}}{2 m}\right) p _ {x} ^ {2} d p _ {x}. \tag {8.18}
$$

The integral in eq. (8.18) can be carried out by the methods discussed in Section 3.10. You could also look up the integral in a table, but it is more fun to work it out by yourself. The result is surprisingly simple,

$$
P V = N \beta^ {- 1}. \tag {8.19}
$$

Eq. (8.19) should be compared with the usual formulation of the ideal gas law,

$$
P V = N k _ {B} T \tag {8.20}
$$

where  $k_{B}$  is known as Boltzmann's constant. This comparison allows us to identify  $\beta$  with the inverse temperature,

$$
\beta = \frac {1}{k _ {B} T}. \tag {8.21}
$$

Because of the Zeroth Law, we can use an ideal-gas thermometer to measure the temperature of anything, so that this expression for  $\beta$  must be universally true.

# 8.4 Temperature Scales

Although we are all familiar with the thermometers that we use every day, the temperature scale in the previous section is rather different than those commonly found in our homes. First of all, eq. (8.2) makes it clear that  $T$  cannot be negative (for an ideal gas), but both temperature scales in common use—Celsius and Fahrenheit—do include negative temperatures.

The Celsius temperature scale is defined by setting the freezing point of water equal to  $0^{\circ}\mathrm{C}$ , and the boiling point of water equal to  $100^{\circ}\mathrm{C}$ . The Celsius temperature is then taken to be a linear function of the temperature  $T$  given in eq. (8.2). Operationally, this could be roughly carried out by trapping a blob of mercury in a glass tube at high temperature, and measuring the position of the mercury in freezing water and in boiling water. I actually carried out this experiment in high school, before people were quite aware of the toxicity of mercury. I do not recommend trying it.

Using the Celsius temperature scale we can extrapolate to zero volume of the gas. Done carefully, it extrapolates to a temperature of  $-273.15^{\circ}\mathrm{C}$ , which is known as 'absolute zero' because it is the lowest possible temperature.

For the rest of this book we will use the Kelvin temperature scale, which is shifted from the Celsius scale to agree with eq. (8.2) and make zero temperature fall at absolute zero,

$$
T (\mathrm {K}) = T \left(^ {\circ} \mathrm {C}\right) + 2 7 3. 1 5. \tag {8.22}
$$

Although eq. (8.22) seems quite simple, it is easy to forget when doing problems. A very common error in examinations is to use the Celsius temperature scale when the Kelvin scale is required.

Since we are following tradition in defining the Celsius and Kelvin temperature scales, the value of Boltzmann's constant is fixed at  $k_{B} = 1.380658 \times 10^{-23} \, \text{J} \, \text{K}^{-1}$ . If we were to have thermometers that measure temperature in Joules, Boltzmann's constant would simply be 1.

# 8.5 The Pressure and the Entropy

From the explicit expression for the entropy of the classical ideal gas in eq. (7.2), we can find the derivative of the entropy with respect to the volume,

$$
\begin{array}{l} \left(\frac {\partial S}{\partial V}\right) _ {E, N} = k N \frac {\partial}{\partial V} \left[ \frac {3}{2} \ln \left(\frac {E}{N}\right) + \ln \left(\frac {V}{N}\right) + X \right] \tag {8.23} \\ = k N \frac {1}{V}. \\ \end{array}
$$

This relationship is only true for the ideal gas. By comparing eq. (8.23) with the ideal gas law, eq. (8.2), we find a simple expression for the partial derivative of entropy with respect to volume that is true for all macroscopic systems

$$
\left(\frac {\partial S}{\partial V}\right) _ {E, N} = \frac {k P}{k _ {B} T}. \tag {8.24}
$$

At this point we will make the standard choice to set the constant  $k$  that we first introduced in eq. (4.15) equal to Boltzmann's constant,  $k = k_{B}$ . Eq. (8.24) now becomes

$$
\left(\frac {\partial S}{\partial V}\right) _ {E, N} = \frac {P}{T}. \tag {8.25}
$$

This is the formal thermodynamic relationship between entropy and pressure.

# 8.6 The Temperature and the Entropy

By comparing eqs. (7.30), (8.12), and (8.21), we can see that

$$
\left(\frac {\partial S}{\partial E}\right) _ {V, N} = k _ {B} \beta = \frac {1}{T}. \tag {8.26}
$$

Because of the Zeroth Law, this relationship must be valid for all thermodynamic systems. It is sometimes used as the definition of temperature in books on thermodynamics, although I have always felt that eq. (8.26) is too abstract to be a reasonable starting point for the study of thermal physics. One of the purposes of the first part of this book is to explain the meaning of eq. (8.26). If that meaning is clear to you at this point, you will be in a good position to begin the study of thermodynamics in the next part of the book.

Since we know the entropy of the classical ideal gas from eq. (7.2), we can evaluate the derivative in eq. (8.26) explicitly:

$$
\begin{array}{l} \left(\frac {\partial S}{\partial E}\right) _ {V, N} = k _ {B} N \frac {\partial}{\partial E} \left[ \frac {3}{2} \ln \left(\frac {E}{N}\right) + \ln \left(\frac {V}{N}\right) + X \right] \\ = k _ {B} N \frac {3}{2 E} = \frac {1}{T}. \tag {8.27} \\ \end{array}
$$

The last equality gives us the energy of the classical ideal gas as a function of temperature

$$
E = \frac {3}{2} N k _ {B} T. \tag {8.28}
$$

An interesting consequence of eq. (8.28) is that the average energy per particle is just

$$
\frac {E}{N} = \frac {3}{2} k _ {B} T \tag {8.29}
$$

which is independent of the particle mass. This is a simple example of the equipartition theorem, which we will return to in Chapter 19.

# 8.7 Equilibrium with Asymmetric Pistons, Revisited

There is an interesting and useful generalization of the equations for equilibrium that can be derived from the entropy. We had assumed that the total volume,  $V_{T} = \sum_{j}V_{j},$  was conserved when systems exchanged volume through a piston. We do not need this restriction.

Suppose systems  $j$  and  $k$  are connected by pistons of unequal cross sections. To be specific, assume that the area of the piston on the 'j' side is  $A_{j}$ , while the area of the piston on the 'k' side is  $A_{k} \neq A_{j}$ . Now the sum of the changes in volume in the two systems does not vanish,  $\Delta V_{j} + \Delta V_{k} = A_{j}\Delta x_{j} + A_{k}\Delta x_{k} \neq 0$ , where  $\Delta x_{\alpha}$  is the distance the piston moves outward. Naturally,  $\Delta x_{j} = -\Delta x_{k}$ . The force on the piston on the 'j' side is  $A_{j}P_{j}$ , where the pressure in system  $j$  is given by

$$
\frac {P _ {j}}{T _ {j}} = \left(\frac {\partial S _ {j}}{\partial V _ {j}}\right) _ {E _ {j}, N _ {j}} \tag {8.30}
$$

and

$$
\frac {1}{T _ {j}} = \left(\frac {\partial S _ {j}}{\partial E _ {j}}\right) _ {V _ {j}, N _ {j}}. \tag {8.31}
$$

The corresponding force on the piston on the  $k$  side is  $A_{k}P_{k}$

Assume that thermal equilibrium has been achieved, so that  $T_{j} = T_{k}$ .

In equilibrium, the forces must be equal,  $A_{j}P_{j} = A_{k}P_{k}$ , so that the pressures are not equal. This implies that

$$
A _ {j} \left(\frac {\partial S _ {j}}{\partial V _ {j}}\right) _ {E _ {j}, N _ {j}} = A _ {j} \frac {P _ {j}}{T _ {j}} = A _ {k} \frac {P _ {k}}{T _ {k}} = A _ {k} \left(\frac {\partial S _ {k}}{\partial V _ {k}}\right) _ {E _ {k}, N _ {k}}. \tag {8.32}
$$

The result is that instead of the usual equilibrium criterion, we have a generalized equilibrium criterion,

$$
A _ {j} \left(\frac {\partial S _ {j}}{\partial V _ {j}}\right) _ {E _ {j}, N _ {j}} = A _ {k} \left(\frac {\partial S _ {k}}{\partial V _ {k}}\right) _ {E _ {k}, N _ {k}}. \tag {8.33}
$$

When  $A_{j} = A_{k}$  we recover the usual expression.

# 8.8 The Entropy and the Chemical Potential

The chemical potential,  $\mu$ , is related to the number of particles in much the same way that the temperature is related to the energy and the pressure is related to the volume. However, while we do have thermometers and pressure gauges, we do not have a convenient way of directly measuring the chemical potential. This makes it difficult to develop our intuition for the meaning of chemical potential in the way we can for temperature and pressure.

On the other hand, it is straightforward to define the chemical potential in analogy with eqs. (8.25) and (8.26),

$$
\left(\frac {\partial S}{\partial N}\right) _ {E, V} = \frac {- \mu}{T}. \tag {8.34}
$$

For the classical ideal gas, we can find an explicit equation for the chemical potential from the equation for the entropy,

$$
\begin{array}{l} \mu = - T \frac {\partial}{\partial N} \left[ k _ {B} N \left[ \frac {3}{2} \ln \left(\frac {E}{N}\right) + \ln \left(\frac {V}{N}\right) + X \right] \right] \\ = - k _ {B} T \left[ \frac {3}{2} \ln \left(\frac {E}{N}\right) + \ln \left(\frac {V}{N}\right) + X \right] - k _ {B} T N \left[ - \frac {3}{2 N} - \frac {1}{N} \right] \\ = - k _ {B} T \left[ \frac {3}{2} \ln \left(\frac {3}{2} k _ {B} T\right) + \ln \left(\frac {V}{N}\right) + X - \frac {5}{2} \right]. \tag {8.35} \\ \end{array}
$$

The complexity of this expression probably adds to the difficulty of acquiring an intuitive feeling for the chemical potential. Unfortunately, that is as much as we can do at this

point. We will revisit the question of what the chemical potential means several times in this book, especially when we discuss Fermi-Dirac and Bose-Einstein statistics in Chapters 27, 28, and 29.

# 8.9 The Fundamental Relation and Equations of State

We have seen that derivatives of the entropy with respect to energy, volume, and number of particles give us three equations for the three variables  $T$ ,  $P$ , and  $\mu$ , so that we have complete information about the behavior of the thermodynamic system. For this reason,

$$
S = S (E, V, N) \tag {8.36}
$$

is called a fundamental relation. Specifically, it is called the fundamental relation in the entropy representation, because the information is given in the functional form of the entropy. There are also other representations of the same complete thermodynamic information that we will discuss in Chapter 12.

The derivatives of the entropy give what are called 'equations of state', because they give information concerning the thermodynamic state of the system. Since there are three derivatives, there are three equations of state for a system containing only one kind of particle. The equations of state for the classical ideal gas are given in eqs. (8.2), (8.28), and (8.35).

Note that although it is quite common to hear  $PV = Nk_{B}T$  referred to as 'the' equation of state, it is only valid for the classical ideal gas, and even then it is only one of three equations of state.

For a general thermodynamic system, the three equations of state are independent. If all three are known, the fundamental relation can be recovered (up to an integration constant).

On the other hand, as we will see in Chapter 13, only two of the equations of state are independent for extensive systems—that is, systems for which the entropy, energy, volume, and number of particles are all proportional to each other. In that case, only two equations of state are needed to recover the fundamental relation.

While the fundamental relation contains complete information about a thermodynamic system, a single equation of state does not. However, equations of state are still very important because, under the right circumstances, one equation of state might have exactly the information required to solve a problem.

# 8.10 The Differential Form of the Fundamental Relation

Much of thermodynamics is concerned with understanding how the properties of a system change in response to small perturbations. For this reason, as well as others that

we will see in later chapters, the differential form of the fundamental relation is very important.

A small change in the entropy due to small changes in the energy, volume, and number of particles can be written formally in terms of partial derivatives

$$
d S = \left(\frac {\partial S}{\partial E}\right) _ {V, N} d E + \left(\frac {\partial S}{\partial V}\right) _ {E, N} d V + \left(\frac {\partial S}{\partial N}\right) _ {E, V} d N. \tag {8.37}
$$

From the equations of state we can rewrite eq. (8.37) in a very useful form:

$$
d S = \left(\frac {1}{T}\right) d E + \left(\frac {P}{T}\right) d V - \left(\frac {\mu}{T}\right) d N. \tag {8.38}
$$

This is known as the differential form of the fundamental relation in the entropy representation. It is valid for all thermodynamic systems.

# 8.11 Thermometers and Pressure Gauges

As mentioned previously, the most important characteristic of a thermometer is that it shows a measurable and reproducible change when its temperature changes.

The next most important characteristic of a thermometer is that it should be small in comparison to the system in which you are interested. Energy will have to flow between the system and the thermometer, but the amount of energy should be small enough so that the temperature of the system of interest does not change.

A 'pressure gauge' must satisfy the same condition of 'smallness'. It must have some observable property that changes with pressure in a known way, and it must be small enough not to affect the pressure in the system being measured.

# 8.12 Reservoirs

In studying thermodynamics it will often be useful to invoke a thermal reservoir at a fixed temperature, so that objects brought into contact with the reservoir will also come to equilibrium at the same temperature. The most important characteristic of a 'reservoir' is that it must be very large in comparison to other systems of interest, so that its temperature does not change significantly when brought into contact with the system of interest.

We will also find it useful to extend the concept of a reservoir to include a source of particles at a fixed chemical potential, or a large container of gas that can maintain a fixed pressure when connected to the system of interest through a piston.

# 8.13 Problems

# PROBLEM 8.1

# Equilibrium between two systems

Consider a mysterious system  $X$ . The energy-dependence of entropy of system  $X$  has been determined to be

$$
S _ {X} (U _ {X}, V _ {X}, N _ {X}) = k _ {B} N _ {X} \left[ A \left(\frac {U _ {X}}{V _ {X}}\right) ^ {1 / 2} + B \right]
$$

where  $A$  and  $B$  are positive constants.

Suppose that system  $X$  has been put into thermal contact with a monatomic ideal gas of  $N$  particles and the composite system has come to equilibrium.

1. Find an equation for  $U_{X}$  in terms of the energy of the ideal gas.

[You do not have to solve the equation.]

2. What is the temperature of the ideal gas as a function of  $U_{X}$ ,  $V_{X}$ , and  $N_{X}$ ?

# PROBLEM 8.2

# Equilibrium between two ideal gases connected by an asymmetric piston

Consider two containers of ideal gas that are connected by a diathermal, asymmetrical piston. In system 1, the piston has a cross-sectional area of  $A_{1}$ , and in system 2 the other end of the piston has a cross-sectional area of  $A_{2}$ . The piston can move freely, changing the volumes of each of the systems. The energies, volumes, and particle numbers are  $E_{1}, V_{1}, N_{1}$  and  $E_{2}, V_{2}, N_{2}$ .

1. Find two equations expressing the equilibrium conditions.  
2. From the equations derived in the first part of the problem, find the relationships between the temperatures of the systems.  
3. From the equations derived in the first part of the problem, find the relationships between the pressures of the systems.